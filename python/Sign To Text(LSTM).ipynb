{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "import sys\n",
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10868125902241690231,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9988323456\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11563577909884304717\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndevice = torch.device(\"cuda\")\\n# import gensim\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\")\n",
    "# import gensim\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# GPU-initialization\n",
    "session = None\n",
    "if (session):\n",
    "    session.close()\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef load_tensor(directions, dir_names, kors, directions_on = False):\\n    '''\\n    tensor 가져오는 방식을 csv에서 가져온 번호에서 부터 불러오도록 설정\\n    output 에 nums는 현재 가져온곳의 한글값을 표현하기 위해서 \\n    '''\\n    h_list = []\\n    answers = []\\n    \\n    for i, dir_name in enumerate(dir_names):\\n            \\n            path = 'output/tensor/'+dir_name\\n            if not (os.path.isdir(path)):\\n                continue\\n                \\n            if directions_on and not directions == '정면':\\n                continue\\n                \\n            h_list.append(torch.load(path+'/hand.pt'))\\n            print(dir_name, kors[i])\\n            answers.append(str(kors[i]))\\n\\n    return h_list, answers\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def load_tensor(directions, dir_names, kors, directions_on = False):\n",
    "    '''\n",
    "    tensor 가져오는 방식을 csv에서 가져온 번호에서 부터 불러오도록 설정\n",
    "    output 에 nums는 현재 가져온곳의 한글값을 표현하기 위해서 \n",
    "    '''\n",
    "    h_list = []\n",
    "    answers = []\n",
    "    \n",
    "    for i, dir_name in enumerate(dir_names):\n",
    "            \n",
    "            path = 'output/tensor/'+dir_name\n",
    "            if not (os.path.isdir(path)):\n",
    "                continue\n",
    "                \n",
    "            if directions_on and not directions == '정면':\n",
    "                continue\n",
    "                \n",
    "            h_list.append(torch.load(path+'/hand.pt'))\n",
    "            print(dir_name, kors[i])\n",
    "            answers.append(str(kors[i]))\n",
    "\n",
    "    return h_list, answers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncsv1 = pd.read_csv(\"output\\\\csv\\\\KETI-2017-SL-0_10480-v2_1.csv\")\\ncsv2 = pd.read_csv(\"output\\\\csv\\\\KETI-2018-SL-Annotation-v1.csv\")\\n\\ndirections = pd.concat([csv1[\\'방향\\'], csv2[\\'방향\\']], ignore_index=True)\\ndirections = directions[:43492]\\n\\ndir_names = pd.concat([csv1[\\'파일명\\'], csv2[\\'파일명\\']], ignore_index=True)\\ndir_names = dir_names[:43492]\\n\\nkors = pd.concat([csv1[\\'한국어\\'], csv2[\\'한국어\\']], ignore_index=True)\\nkors = kors[:43492]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "csv1 = pd.read_csv(\"output\\csv\\KETI-2017-SL-0_10480-v2_1.csv\")\n",
    "csv2 = pd.read_csv(\"output\\csv\\KETI-2018-SL-Annotation-v1.csv\")\n",
    "\n",
    "directions = pd.concat([csv1['방향'], csv2['방향']], ignore_index=True)\n",
    "directions = directions[:43492]\n",
    "\n",
    "dir_names = pd.concat([csv1['파일명'], csv2['파일명']], ignore_index=True)\n",
    "dir_names = dir_names[:43492]\n",
    "\n",
    "kors = pd.concat([csv1['한국어'], csv2['한국어']], ignore_index=True)\n",
    "kors = kors[:43492]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(dir_path = [\".\", \"output\", \"tensor\"]):\n",
    "    '''\n",
    "    tensor 가져오는 방식을 csv에서 가져온 번호에서 부터 불러오도록 설정\n",
    "    output 에 nums는 현재 가져온곳의 한글값을 표현하기 위해서 \n",
    "    '''\n",
    "    dir_path = os.path.join(*dir_path)\n",
    "    tensor_folders = sorted(os.listdir(dir_path))\n",
    "    print(tensor_folders[1:9])\n",
    "    h_list = []\n",
    "    answers = []\n",
    "    \n",
    "    # 0 ~ 7 순회\n",
    "    for tensor_folder in tensor_folders[1:9]:\n",
    "        tensors_path = os.path.join(dir_path + \"/\" + tensor_folder)\n",
    "        tensors = sorted(os.listdir(tensors_path))\n",
    "        \n",
    "        # 각각의 숫자 순회\n",
    "        for tensor in tensors:\n",
    "            h_list.append(torch.load(tensors_path + \"/\" + tensor + \"/hand.pt\"))\n",
    "            answers.append(tensor_folder)\n",
    "            \n",
    "\n",
    "    return h_list, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_tensor_aihub(dir_path = [\".\", \"output\", \"csv\"]):\n",
    "    '''\n",
    "    tensor 가져오는 방식을 csv에서 가져온 번호에서 부터 불러오도록 설정\n",
    "    output 에 nums는 현재 가져온곳의 한글값을 표현하기 위해서 \n",
    "    '''\n",
    "    \n",
    "    dir_path = os.path.join(*dir_path)\n",
    "    tensor_folders = sorted(os.listdir(dir_path))\n",
    "    \n",
    "    \n",
    "    # 0 ~ 7 순회\n",
    "    for tensor_folder in tensor_folders:\n",
    "        if 'v2_1_num' in tensor_folder:\n",
    "            num_csv = pd.read_csv(os.path.join(dir_path, tensor_folder))\n",
    "\n",
    "            \n",
    "    num_csv = num_csv[num_csv['한국어'] <= 7]  # 7 이하만 남김\n",
    "    answers = []\n",
    "    \n",
    "    dir_path = os.path.join('.', 'dummy')\n",
    "    tensor_folders = sorted(os.listdir(dir_path))\n",
    "    \n",
    "#     h_list = [''] * len(tensor_folders)\n",
    "    h_list = []\n",
    "    num_csv['파일명'] = num_csv['파일명'].map(lambda x : x.split('.')[0])\n",
    "\n",
    "    print(num_csv[:10])\n",
    "    \n",
    "    print('fuck', num_csv.loc[102]['한국어'])\n",
    "    \n",
    "          \n",
    "    for tensor_folder in tensor_folders:\n",
    "        if 'KETI' in tensor_folder :\n",
    "            idx = num_csv.index[tensor_folder == num_csv['파일명']].tolist()\n",
    "            \n",
    "            if len(idx) != 0:\n",
    "                tensors_path = os.path.join(dir_path + \"\\\\\" + tensor_folder)\n",
    "                tensors = sorted(os.listdir(tensors_path))        \n",
    "\n",
    "                lh = torch.load(tensors_path + \"\\\\\" + \"\\\\left_hand.pt\")\n",
    "                rh = torch.load(tensors_path + \"\\\\\" + \"\\\\right_hand.pt\")\n",
    "#                 print(idx[0])\n",
    "                h_list.append(torch.cat([lh, rh], dim=1))  \n",
    "                answers.append(str(num_csv.loc[idx[0]]['한국어']))\n",
    "    print(len(answers))\n",
    "            \n",
    "\n",
    "    return h_list, answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "load_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "h_list, answers = load_tensor()\n",
    "answer_set = list(map(str, sorted(map(int, list(set(answers))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자 0 : 117\n",
      "숫자 1 : 117\n",
      "숫자 2 : 117\n",
      "숫자 3 : 117\n",
      "숫자 4 : 120\n",
      "숫자 5 : 123\n",
      "숫자 6 : 120\n",
      "숫자 7 : 123\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(\"숫자\", i, \":\", answers.count(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 42, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchFrame(lst, max_frame):\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].view(lst[i].shape[0], -1)\n",
    "        lst[i] = np.array(F.pad(lst[i], (0, 0, 0, max_frame - lst[i].shape[0]), value=0))\n",
    "        \n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "mx = 0\n",
    "for i in h_list:\n",
    "       mx = max(mx, i.shape[0])\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2d3eb3b936e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhand_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatchFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m71\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-d56ecf8c306c>\u001b[0m in \u001b[0;36mmatchFrame\u001b[1;34m(lst, max_frame)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_frame\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "hand_data = matchFrame(h_list, 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(hand_data, answers, test_size=0.4, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "print(answer_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "test = encoder.fit_transform(answer_set)\n",
    "\n",
    "y_train = encoder.transform(y_train)\n",
    "y_val = encoder.transform(y_val)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 71, 126)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 71, 256)           261120    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 71, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 71, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 71, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 71, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 71, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 71, 256)           656384    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 71, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "class_output (Dense)         (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 4,597,768\n",
      "Trainable params: 4,597,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "dropout = 0.2\n",
    "num_classes = len(answer_set)\n",
    "nodesizes = [256, 256, 128]\n",
    "\n",
    "inputs = keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "lstm = Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
    "lstm = layers.Dropout(rate=dropout)(lstm)  \n",
    "\n",
    "for i in range(0,3):    #number of layers random between 1 an 3\n",
    "    lstm = Bidirectional(layers.LSTM(nodesizes[i],return_sequences=True))(lstm)\n",
    "    lstm = layers.Dropout(rate=dropout)(lstm)\n",
    "\n",
    "lstm = Bidirectional(layers.LSTM(256))(lstm)\n",
    "lstm = layers.Dropout(rate=dropout)(lstm)\n",
    "class_output = layers.Dense(num_classes, activation='softmax', name='class_output')(lstm)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=[class_output])\n",
    "# Plot the model graph\n",
    "#keras.utils.plot_model(model, 'nn_graph.png', show_shapes=True)\n",
    "\n",
    "model.compile(loss={\n",
    "    'class_output': 'categorical_crossentropy', \n",
    "    },\n",
    "    optimizer='Adamax',\n",
    "    metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 24s 308ms/step - loss: 2.0250 - accuracy: 0.1676 - precision_1: 0.1679 - recall_1: 0.0021 - val_loss: 1.8798 - val_accuracy: 0.1728 - val_precision_1: 0.5294 - val_recall_1: 0.0471\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 1.5936 - accuracy: 0.3222 - precision_1: 0.5863 - recall_1: 0.0781 - val_loss: 1.5660 - val_accuracy: 0.3141 - val_precision_1: 0.7000 - val_recall_1: 0.1466\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 1.3868 - accuracy: 0.3834 - precision_1: 0.6877 - recall_1: 0.2034 - val_loss: 1.0315 - val_accuracy: 0.5497 - val_precision_1: 0.7432 - val_recall_1: 0.2880\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.9618 - accuracy: 0.5352 - precision_1: 0.6753 - recall_1: 0.3133 - val_loss: 0.9657 - val_accuracy: 0.5236 - val_precision_1: 0.5143 - val_recall_1: 0.2827\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.7494 - accuracy: 0.6181 - precision_1: 0.7126 - recall_1: 0.4979 - val_loss: 1.6761 - val_accuracy: 0.3351 - val_precision_1: 0.3865 - val_recall_1: 0.3298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 1.2419 - accuracy: 0.4828 - precision_1: 0.5269 - recall_1: 0.4316 - val_loss: 0.6543 - val_accuracy: 0.7539 - val_precision_1: 0.8630 - val_recall_1: 0.6597\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.6916 - accuracy: 0.7240 - precision_1: 0.7831 - recall_1: 0.5797 - val_loss: 0.4985 - val_accuracy: 0.7435 - val_precision_1: 0.7765 - val_recall_1: 0.7277\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.3862 - accuracy: 0.8407 - precision_1: 0.8655 - recall_1: 0.8059 - val_loss: 0.3132 - val_accuracy: 0.8429 - val_precision_1: 0.8541 - val_recall_1: 0.8272\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.3117 - accuracy: 0.8689 - precision_1: 0.8746 - recall_1: 0.8522 - val_loss: 0.3323 - val_accuracy: 0.8429 - val_precision_1: 0.8503 - val_recall_1: 0.8325\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.2841 - accuracy: 0.8905 - precision_1: 0.8909 - recall_1: 0.8903 - val_loss: 0.5683 - val_accuracy: 0.7958 - val_precision_1: 0.8000 - val_recall_1: 0.7958\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.6661 - accuracy: 0.7715 - precision_1: 0.7775 - recall_1: 0.7661 - val_loss: 0.3169 - val_accuracy: 0.8953 - val_precision_1: 0.9081 - val_recall_1: 0.8796\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.4027 - accuracy: 0.8551 - precision_1: 0.8571 - recall_1: 0.8430 - val_loss: 0.1863 - val_accuracy: 0.9529 - val_precision_1: 0.9529 - val_recall_1: 0.9529\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.1530 - accuracy: 0.9641 - precision_1: 0.9641 - recall_1: 0.9638 - val_loss: 0.0860 - val_accuracy: 0.9686 - val_precision_1: 0.9686 - val_recall_1: 0.9686\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0724 - accuracy: 0.9879 - precision_1: 0.9879 - recall_1: 0.9879 - val_loss: 0.2885 - val_accuracy: 0.9005 - val_precision_1: 0.9005 - val_recall_1: 0.9005\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.2075 - accuracy: 0.8996 - precision_1: 0.9005 - recall_1: 0.8996 - val_loss: 0.1353 - val_accuracy: 0.9738 - val_precision_1: 0.9738 - val_recall_1: 0.9738\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.1492 - accuracy: 0.9571 - precision_1: 0.9571 - recall_1: 0.9571 - val_loss: 0.3972 - val_accuracy: 0.8272 - val_precision_1: 0.8404 - val_recall_1: 0.8272\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.2790 - accuracy: 0.8744 - precision_1: 0.8761 - recall_1: 0.8727 - val_loss: 0.1663 - val_accuracy: 0.9424 - val_precision_1: 0.9474 - val_recall_1: 0.9424\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.2594 - accuracy: 0.9044 - precision_1: 0.9044 - recall_1: 0.9044 - val_loss: 0.2304 - val_accuracy: 0.9005 - val_precision_1: 0.9053 - val_recall_1: 0.9005\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0932 - accuracy: 0.9662 - precision_1: 0.9695 - recall_1: 0.9662 - val_loss: 0.0962 - val_accuracy: 0.9581 - val_precision_1: 0.9581 - val_recall_1: 0.9581\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.0626 - accuracy: 0.9907 - precision_1: 0.9907 - recall_1: 0.9907 - val_loss: 0.0735 - val_accuracy: 0.9791 - val_precision_1: 0.9791 - val_recall_1: 0.9791\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0309 - accuracy: 0.9966 - precision_1: 0.9966 - recall_1: 0.9966 - val_loss: 0.0888 - val_accuracy: 0.9738 - val_precision_1: 0.9738 - val_recall_1: 0.9738\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.0861 - accuracy: 0.9756 - precision_1: 0.9756 - recall_1: 0.9756 - val_loss: 0.1269 - val_accuracy: 0.9476 - val_precision_1: 0.9476 - val_recall_1: 0.9476\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.4381 - accuracy: 0.8530 - precision_1: 0.8557 - recall_1: 0.8527 - val_loss: 0.1873 - val_accuracy: 0.9581 - val_precision_1: 0.9581 - val_recall_1: 0.9581\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.2830 - accuracy: 0.8944 - precision_1: 0.9004 - recall_1: 0.8919 - val_loss: 0.1715 - val_accuracy: 0.9529 - val_precision_1: 0.9731 - val_recall_1: 0.9476\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.1184 - accuracy: 0.9691 - precision_1: 0.9719 - recall_1: 0.9678 - val_loss: 0.0894 - val_accuracy: 0.9791 - val_precision_1: 0.9791 - val_recall_1: 0.9791\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 0.0505 - accuracy: 0.9885 - precision_1: 0.9885 - recall_1: 0.9885 - val_loss: 0.0523 - val_accuracy: 0.9843 - val_precision_1: 0.9842 - val_recall_1: 0.9791\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0242 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9843\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0170 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0585 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9843\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.0133 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9843\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.0097 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9895 - val_precision_1: 0.9947 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0082 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9843 - val_precision_1: 0.9895 - val_recall_1: 0.9843\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0108 - accuracy: 0.9973 - precision_1: 0.9973 - recall_1: 0.9973 - val_loss: 0.0359 - val_accuracy: 0.9895 - val_precision_1: 0.9947 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0129 - accuracy: 0.9983 - precision_1: 0.9983 - recall_1: 0.9983 - val_loss: 0.0757 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9843\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.1071 - accuracy: 0.9720 - precision_1: 0.9720 - recall_1: 0.9720 - val_loss: 0.0318 - val_accuracy: 0.9948 - val_precision_1: 0.9948 - val_recall_1: 0.9948\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0318 - accuracy: 0.9931 - precision_1: 0.9931 - recall_1: 0.9915 - val_loss: 0.0293 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0111 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9843 - val_precision_1: 0.9843 - val_recall_1: 0.9843\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.0066 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.0050 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.0042 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0041 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0040 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.0036 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.0033 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.0030 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0028 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0027 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0024 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0023 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9895 - val_precision_1: 0.9895 - val_recall_1: 0.9895\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "checkpoint = ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, mode = 'max', save_best_only=True, save_weights_only=False, period=1)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=30, \n",
    "    validation_data=(x_val,y_val), \n",
    "    callbacks = [checkpoint],\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 도화지 생성\n",
    "fig = plt.figure()\n",
    "# 정확도 그래프 그리기\n",
    "plt.plot(range(50), history.history['val_accuracy'], label='Accuracy', color='darkred')\n",
    "# 축 이름\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('검증 정확도(%)')\n",
    "plt.title('epoch에 따른 검증 데이터에 대한 정확도 그래프')\n",
    "plt.grid(linestyle='--', color='lavender')\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "# 그래프 저장\n",
    "plt.savefig('sign_launguage_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prec = []\n",
    "\n",
    "pred_datas_path = os.path.join('.', 'output', 'tensor', 'num')\n",
    "pred_datas = sorted(os.listdir(pred_datas_path))\n",
    "\n",
    "for pred_data in pred_datas:\n",
    "    pred_data_path = pred_datas_path + \"\\\\\" + pred_data\n",
    "    for data in os.listdir(pred_data_path):\n",
    "        prec.append(torch.load(pred_data_path + \"\\\\\" + data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = matchFrame(prec, 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 71, 126)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 126)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st data :  1\n",
      "2st data :  0\n",
      "3st data :  2\n",
      "4st data :  3\n",
      "5st data :  4\n",
      "6st data :  5\n",
      "7st data :  7\n",
      "8st data :  7\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(model.predict(prec)):\n",
    "    print(str(i+1) + \"st data : \", np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
