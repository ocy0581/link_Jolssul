{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install mediapipe\n",
    "# !pip install cv2b\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "images = {\"pose1\":cv2.imread(\"./img/img1.png\"),\"pose2\":cv2.imread(\"./img/img2.png\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, image in images.items():\n",
    "#     print(name)   \n",
    "    cv2.imshow(name,image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "\n",
    "# Initialize MediaPipe Holistic.\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=True, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DrawingSpec for drawing the face landmarks later.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = cv2.cvtColor(images['pose1'],cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.imshow(\"1\",tmp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nose coordinates: (145.01178741455078, 450.2285957336426)\n",
      "Pose landmarks of pose1:\n",
      "Nose coordinates: (339.4797897338867, 340.8392143249512)\n",
      "Pose landmarks of pose2:\n"
     ]
    }
   ],
   "source": [
    "for name, image in images.items():\n",
    "# Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print nose coordinates.\n",
    "    image_hight, image_width, _ = image.shape\n",
    "    if results.pose_landmarks:\n",
    "        print(\n",
    "        f'Nose coordinates: ('\n",
    "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\n",
    "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_hight})'\n",
    "        )\n",
    "# Draw pose landmarks.\n",
    "    print(f'Pose landmarks of {name}:')\n",
    "    annotated_image = image.copy()\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=annotated_image, \n",
    "        landmark_list=results.face_landmarks, \n",
    "        connections=mp_holistic.FACE_CONNECTIONS,\n",
    "        landmark_drawing_spec=drawing_spec,\n",
    "        connection_drawing_spec=drawing_spec)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=annotated_image, \n",
    "        landmark_list=results.pose_landmarks, \n",
    "        connections=mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=drawing_spec,\n",
    "        connection_drawing_spec=drawing_spec)\n",
    "    cv2.imshow(name,annotated_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "mp_holistic = mp.solutions.holistic\n",
    "video_hol = mp.solutions.holistic.Holistic(static_image_mode=False,upper_body_only=False,smooth_landmarks=True,\n",
    "                                           min_detection_confidence=0.5,min_tracking_confidence=0.5)\n",
    "# Prepare DrawingSpec for drawing the face landmarks later.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비디오 종료\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# try:\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #\n",
    "    results = video_hol.process(image=frame)\n",
    "    \n",
    "    mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "#     print(results)\n",
    "#     print(results.left_hand_landmarks)\n",
    "#     print(results.)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=frame, \n",
    "        landmark_list=results.face_landmarks, \n",
    "        connections=mp_holistic.FACE_CONNECTIONS,\n",
    "        landmark_drawing_spec=drawing_spec,\n",
    "        connection_drawing_spec=drawing_spec)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=frame, \n",
    "        landmark_list=results.pose_landmarks, \n",
    "        connections=mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=drawing_spec,\n",
    "        connection_drawing_spec=drawing_spec)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# except Exception as e:\n",
    "#     print(e)    \n",
    "# When everything is done, release the capture\n",
    "#     video_capture.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘되는 버전\n",
    "\n",
    "# For webcam input:\n",
    "holistic = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "    # If loading a video, use 'break' instead of 'continue'.\n",
    "        continue\n",
    "    print(type(image))\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    cv2.imshow('MediaPipe Holistic', image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "holistic.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}