{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수화 동영상 파일 -> 텐서 파일(+ 미디어파이프 처리 영상 파일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모션 랜드마크를 리스트로 반환\n",
    "def convert_landmark_to_tensor(landmarks, n_point):\n",
    "    # 영상에 모션이 잡힐 경우 \n",
    "    if landmarks: \n",
    "        motion_location = []\n",
    "        for lm in landmarks.landmark:\n",
    "            motion_location.append([lm.x, lm.y, lm.z])\n",
    "        \n",
    "        return motion_location\n",
    "        \n",
    "    # 영상에 모션이 잡히지 않을 경우\n",
    "    else:\n",
    "        return [[0] * 3 for _ in range(n_point)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensor_and_video(input_video_path, output_tensor_path, output_video_path, video_save=False):\n",
    "    \n",
    "    # Prepare DrawingSpec\n",
    "    mp_drawing = mp.solutions.drawing_utils \n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "    # Config holistic\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    holistic = mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    \n",
    "    # 영상 가져오기\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # 영상 저장 1\n",
    "    if video_save:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V') # 영상 포맷\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (1280,720)) # 비디오 경로, 영상 포맷, 초당 프레임, width*height \n",
    "\n",
    "    # 영상 width, height 설정\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    # 각 요소(왼손, 오른손, 얼굴, 포즈) 좌표 저장 리스트\n",
    "    left_hand_list = []\n",
    "    right_hand_list = []\n",
    "    face_list = []\n",
    "    pose_list = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        success, image = cap.read() \n",
    "\n",
    "        if not success: # 동영상 끝\n",
    "            break\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "          image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "          image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "          image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "          image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "        \n",
    "        # 각 랜드마크를 리스트로 변환 후 리스트에 저장\n",
    "        left_hand_list.append(convert_landmark_to_tensor(results.left_hand_landmarks, 21))\n",
    "        right_hand_list.append(convert_landmark_to_tensor(results.right_hand_landmarks, 21))\n",
    "        face_list.append(convert_landmark_to_tensor(results.face_landmarks, 468))\n",
    "        pose_list.append(convert_landmark_to_tensor(results.pose_landmarks, 33))\n",
    "            \n",
    "        # 영상 저장 2 (실질적인 영상 쓰기)\n",
    "        if video_save:\n",
    "            out.write(image)\n",
    "\n",
    "    # 텐서로 변환\n",
    "    left_hand_tensor = torch.FloatTensor(left_hand_list)\n",
    "    right_hand_tensor = torch.FloatTensor(right_hand_list)\n",
    "    face_tensor = torch.FloatTensor(face_list)\n",
    "    pose_tensor = torch.FloatTensor(pose_list)\n",
    "    \n",
    "    # 텐서를 저장할 디렉토리 생성\n",
    "    if not(os.path.isdir(output_tensor_path)):\n",
    "        os.mkdir(output_tensor_path)\n",
    "        \n",
    "    # 텐서 파일 저장\n",
    "    torch.save(left_hand_tensor, os.path.join(output_tensor_path, \"left_hand.pt\"))\n",
    "    torch.save(right_hand_tensor, os.path.join(output_tensor_path, \"right_hand.pt\"))\n",
    "    torch.save(face_tensor, os.path.join(output_tensor_path, \"face.pt\"))\n",
    "    torch.save(pose_tensor, os.path.join(output_tensor_path, \"pose.pt\"))\n",
    "    \n",
    "    if video_save:\n",
    "        # 동영사을 저장할 디렉토리 생성\n",
    "        if not(os.path.isdir(output_video_path)):\n",
    "            os.mkdir(output_video_path)\n",
    "        \n",
    "        # 영상 저장 3\n",
    "        if video_save:\n",
    "            out.release()\n",
    "\n",
    "    holistic.close()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 디렉토리 생성 함수\n",
    "def mkdirs(file_path_list: list, verbose=True):\n",
    "    # ex) file_path_list= [\".\", \"output\", \"images\"]\n",
    "    \n",
    "    file_path = \"\"  # 생성할 디렉토리\n",
    "    for path in file_path_list:\n",
    "        file_path = os.path.join(file_path, path)\n",
    "        \n",
    "        # 디렉토리가 없다면 생성\n",
    "        if not(os.path.isdir(file_path)):\n",
    "            # 디렉토리 생성 안내 문구 출력\n",
    "            if verbose:\n",
    "                print(\"No {}\".format(file_path))\n",
    "                print(\"Make directory {}\".format(file_path))\n",
    "                print()\n",
    "                \n",
    "            # 디렉토리 생성\n",
    "            os.mkdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_videos_to_tensor(input_video_path_list=[\".\", \"videos\"],\n",
    "                             output_tensor_path_list=[\".\", \"output\", \"tensor\"],\n",
    "                             output_video_path_list=[\".\", \"output\", \"video\"],\n",
    "                             videos_save=False):\n",
    "    \n",
    "    # 디렉토리 풀내임 생성\n",
    "    input_video_path = os.path.join(*input_video_path_list)\n",
    "    output_tensor_path = os.path.join(*output_tensor_path_list)\n",
    "    output_video_path = os.path.join(*output_video_path_list)\n",
    "\n",
    "    # 안내 문구 출력\n",
    "    print(\"{:20}{}\".format(\"intput_video_path: \", input_video_path))\n",
    "    print(\"{:20}{}\".format(\"output_tensor_path: \", output_tensor_path))\n",
    "    print(\"{:20}{}\".format(\"videos_save: \", str(videos_save)))\n",
    "    if videos_save:\n",
    "        print(\"{:20}{}\".format(\"output_video_path: \", output_video_path))\n",
    "    print()\n",
    "    \n",
    "    # 디렉토리 생성\n",
    "    mkdirs(input_video_path_list)\n",
    "    mkdirs(output_tensor_path_list)\n",
    "    if videos_save:\n",
    "        mkdirs(output_video_path_list)\n",
    "\n",
    "    # 각 비디오 파일 \n",
    "    videos = os.listdir(input_video_path)\n",
    "    videos.sort()\n",
    "\n",
    "    # 동영상의 모션을 텐서로 변환\n",
    "    for i, video in enumerate(videos):\n",
    "        make_tensor_and_video(os.path.join(input_video_path, video),\n",
    "                              os.path.join(output_tensor_path, video[:-4]),  # [:-4]: 확장자 제거\n",
    "                              os.path.join(output_video_path, video),\n",
    "                              videos_save)\n",
    "        if i%5==0:\n",
    "            print(\"{}/{} videos completed\".format(i, len(videos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intput_video_path:  ./videos\n",
      "output_tensor_path: ./output/tensor\n",
      "videos_save:        False\n",
      "\n",
      "0/21 videos completed\n",
      "5/21 videos completed\n",
      "10/21 videos completed\n",
      "15/21 videos completed\n",
      "20/21 videos completed\n"
     ]
    }
   ],
   "source": [
    "# 동영상 개장 3~5초 정도 소요\n",
    "# ex) 동영상 50개: 4분 소요\n",
    "convert_videos_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 21, 3])\n",
      "torch.Size([160, 21, 3])\n",
      "torch.Size([160, 33, 3])\n",
      "torch.Size([160, 468, 3])\n"
     ]
    }
   ],
   "source": [
    "# shape 확인\n",
    "print(torch.load(\"./output/tensor/KETI_SL_0000000002/left_hand.pt\").shape)\n",
    "print(torch.load(\"./output/tensor/KETI_SL_0000000002/right_hand.pt\").shape)\n",
    "print(torch.load(\"./output/tensor/KETI_SL_0000000002/pose.pt\").shape)\n",
    "print(torch.load(\"./output/tensor/KETI_SL_0000000002/face.pt\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4976,  0.2136, -0.8674],\n",
      "         [ 0.5105,  0.1642, -0.8141],\n",
      "         [ 0.5222,  0.1617, -0.8142],\n",
      "         ...,\n",
      "         [ 0.4254,  1.9055,  0.2465],\n",
      "         [ 0.5679,  1.9551, -0.2476],\n",
      "         [ 0.4383,  1.9436, -0.0123]],\n",
      "\n",
      "        [[ 0.4934,  0.2121, -0.7493],\n",
      "         [ 0.5069,  0.1636, -0.7004],\n",
      "         [ 0.5184,  0.1612, -0.7005],\n",
      "         ...,\n",
      "         [ 0.4328,  1.8615,  0.1323],\n",
      "         [ 0.5596,  1.9070, -0.2900],\n",
      "         [ 0.4418,  1.9000, -0.1024]],\n",
      "\n",
      "        [[ 0.4959,  0.2109, -0.7550],\n",
      "         [ 0.5092,  0.1620, -0.7042],\n",
      "         [ 0.5207,  0.1596, -0.7043],\n",
      "         ...,\n",
      "         [ 0.4285,  1.8531,  0.1467],\n",
      "         [ 0.5592,  1.8996, -0.2816],\n",
      "         [ 0.4397,  1.8897, -0.0702]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4917,  0.2157, -0.8534],\n",
      "         [ 0.5045,  0.1680, -0.8078],\n",
      "         [ 0.5158,  0.1655, -0.8078],\n",
      "         ...,\n",
      "         [ 0.4347,  1.9247,  0.3189],\n",
      "         [ 0.5718,  1.9957, -0.1753],\n",
      "         [ 0.4467,  1.9968,  0.0181]],\n",
      "\n",
      "        [[ 0.4917,  0.2157, -0.8493],\n",
      "         [ 0.5045,  0.1680, -0.8047],\n",
      "         [ 0.5158,  0.1655, -0.8048],\n",
      "         ...,\n",
      "         [ 0.4350,  1.9246,  0.3125],\n",
      "         [ 0.5758,  1.9955, -0.1903],\n",
      "         [ 0.4467,  1.9967,  0.0165]],\n",
      "\n",
      "        [[ 0.4916,  0.2157, -0.8476],\n",
      "         [ 0.5045,  0.1680, -0.8026],\n",
      "         [ 0.5158,  0.1655, -0.8027],\n",
      "         ...,\n",
      "         [ 0.4345,  1.9244,  0.2992],\n",
      "         [ 0.5743,  1.9948, -0.2236],\n",
      "         [ 0.4461,  1.9966,  0.0098]]])\n"
     ]
    }
   ],
   "source": [
    "# face 좌표 확인\n",
    "pose_tensor = torch.load(\"./output/tensor/KETI_SL_0000000002/pose.pt\")\n",
    "print(pose_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 가장 바깥 리스트만 텐서로 바뀌고 텐서 내부는 전부 리스트임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
