{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7427329975193420701,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 317608306992960514\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 6814280843129280077\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, warnings, sklearn, matplotlib, torch, time, cv2, math, sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from matplotlib import pyplot\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# GPU-initialization\n",
    "session = None\n",
    "if (session):\n",
    "    session.close()\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(dir_path = [\".\", \"output\", \"tensor\"]):\n",
    "    '''\n",
    "    tensor 가져오는 방식을 csv에서 가져온 번호에서 부터 불러오도록 설정\n",
    "    output 에 nums는 현재 가져온곳의 한글값을 표현하기 위해서 \n",
    "    '''\n",
    "    dir_path = os.path.join(*dir_path)\n",
    "    tensor_folders = sorted(os.listdir(dir_path))\n",
    "    \n",
    "    h_list = []\n",
    "    answers = []\n",
    "    \n",
    "    # 0 ~ 7 순회\n",
    "    for tensor_folder in tensor_folders:\n",
    "        if tensor_folder == \"prediction\":\n",
    "            continue\n",
    "            \n",
    "        if tensor_folder == \"aihub\":\n",
    "            continue\n",
    "                \n",
    "        tensors_path = os.path.join(dir_path + \"\\\\\" + tensor_folder)\n",
    "        tensors = sorted(os.listdir(tensors_path))\n",
    "        \n",
    "        \n",
    "        # 각각의 숫자 순회\n",
    "        for tensor in tensors:                \n",
    "            h_list.append(torch.load(tensors_path + \"\\\\\" + tensor + \"\\\\hand.pt\"))\n",
    "            #h_list.append(torch.load(tensors_path + \"\\\\\" + tensor + \"\\\\hp.pt\"))\n",
    "            answers.append(tensor_folder)\n",
    "            \n",
    "\n",
    "    return h_list, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_list, answers = load_tensor() # 훈련데이터\n",
    "answer_set = list(map(str, sorted(list(set(answers))))) # 정답데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 최대 길이 설정(각 영상의 최대 프레임 추출 후 이를 적용)\n",
    "def matchFrame(lst, max_frame):\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].view(lst[i].shape[0], -1)\n",
    "        lst[i] = np.array(F.pad(lst[i], (0, 0, 0, max_frame - lst[i].shape[0]), value=0))\n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스 최대 길이 출력\n",
    "mx = 0\n",
    "for i in h_list:\n",
    "       mx = max(mx, i.shape[0])\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 최대길이 설정\n",
    "hand_data = matchFrame(h_list, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 126)\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 Shape\n",
    "print(hand_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(hand_data, answers, test_size=0.075, random_state=42)\n",
    "#x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '가끔', '가렵다', '가슴', '감기', '감사합니다', '고열', '골절', '교통사고', '구내염', '귀', '근육통', '눈', '다리', '두드러기', '두통', '등', '따끔거리다', '멍들다', '목', '몸', '몸살', '무릎', '물다', '발목', '부러지다', '붕대', '뼈', '사마귀', '설사', '소화불량', '손', '수술', '심장마비', '쓰러지다', '아프다', '안녕하세요', '어깨', '어지럽다', '얼굴', '열', '의사', '임신', '자주', '찰과상', '코로나', '탈구', '탈모', '토하다', '파상풍', '피', '피부', '허리', '호흡곤란', '화상']\n"
     ]
    }
   ],
   "source": [
    "print(answer_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5697, 129, 126)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 원핫인코딩\n",
    "encoder = LabelBinarizer()\n",
    "test = encoder.fit_transform(answer_set)\n",
    "\n",
    "y_train = encoder.transform(y_train)\n",
    "y_val = encoder.transform(y_val)\n",
    "#y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5697, 62)\n"
     ]
    }
   ],
   "source": [
    "# 정답 데이터 shape\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바다나우 어텐션\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = Dense(units)\n",
    "    self.W2 = Dense(units)\n",
    "    self.V = Dense(1)\n",
    "\n",
    "  def call(self, values, query): # 단, key와 value는 같음\n",
    "    # query shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Unit\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv1D(filters, 3, strides=strides,\n",
    "            \t\t\t\t\tpadding=\"same\", activation = \"relu\",use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            #self.activation,\n",
    "            keras.layers.Conv1D(filters, 3, strides=1,\n",
    "            \t\t\t\t\tpadding=\"same\", use_bias=False),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv1D(filters, 1, strides=strides,\n",
    "                                    padding=\"same\", use_bias=False),\n",
    "                keras.layers.BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 129, 126)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 129, 32)      12128       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 129, 32)      128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 129, 32)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 64, 32)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "residual_unit (ResidualUnit)    (None, 64, 32)       6400        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 31, 32)       0           residual_unit[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "residual_unit_1 (ResidualUnit)  (None, 16, 64)       21248       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 7, 64)        0           residual_unit_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 7, 256)       197632      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 7, 256)       0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 7, 128)       164352      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 128)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 7, 128)       98816       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 128)       0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 7, 128), (No 98816       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt ((None, 128), (None, 16577       bidirectional_3[0][0]            \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        bahdanau_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "class_output (Dense)            (None, 62)           4030        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 628,383\n",
      "Trainable params: 627,807\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "dropout = 0.25\n",
    "num_classes = len(answer_set)\n",
    "nodesizes = [64, 64]\n",
    "\n",
    "inputs = keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "conv1 = keras.layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(\"relu\")(conv1)\n",
    "conv1 = keras.layers.MaxPool1D(pool_size=3, strides=2)(conv1)\n",
    "\n",
    "conv1 = ResidualUnit(32, 1)(conv1)\n",
    "conv1 = keras.layers.MaxPool1D(pool_size=3, strides=2)(conv1)\n",
    "\n",
    "conv1 = ResidualUnit(64, 2)(conv1)\n",
    "conv1 = keras.layers.MaxPool1D(pool_size=3, strides=2)(conv1)\n",
    "\n",
    "lstm = Bidirectional(layers.LSTM(128, return_sequences=True))(conv1)\n",
    "lstm = layers.Dropout(rate=dropout)(lstm)  \n",
    "\n",
    "for i in range(0,2):    #number of layers random between 1 an 3\n",
    "    lstm = Bidirectional(layers.LSTM(nodesizes[i],return_sequences=True))(lstm)\n",
    "    lstm = layers.Dropout(rate=dropout)(lstm)\n",
    "\n",
    "#lstm = Bidirectional(layers.LSTM(256))(lstm)\n",
    "#lstm = layers.Dropout(rate=dropout)(lstm)\n",
    "\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
    "  (layers.LSTM(64, return_sequences=True, return_state=True))(lstm)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
    "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태\n",
    "\n",
    "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
    "\n",
    "context_vector, attention_weights = attention(lstm, state_h)\n",
    "dense1 = Dense(64, activation=\"relu\")(context_vector)\n",
    "dropout = layers.Dropout(0.)(dense1)\n",
    "\n",
    "class_output = layers.Dense(num_classes, activation='softmax', name='class_output')(dense1)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=[class_output])\n",
    "# Plot the model graph\n",
    "keras.utils.plot_model(model, 'nn_graph.png', show_shapes=True)\n",
    "\n",
    "model.compile(loss={\n",
    "    'class_output': 'categorical_crossentropy', \n",
    "    },\n",
    "    optimizer='Adamax',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 3.3152 - accuracy: 0.1460 - val_loss: 2.9424 - val_accuracy: 0.1732\n",
      "Epoch 2/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 1.8131 - accuracy: 0.4738 - val_loss: 1.8672 - val_accuracy: 0.4113\n",
      "Epoch 3/45\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 1.1227 - accuracy: 0.6862 - val_loss: 1.0314 - val_accuracy: 0.6970\n",
      "Epoch 4/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.7203 - accuracy: 0.8011 - val_loss: 0.6342 - val_accuracy: 0.8247\n",
      "Epoch 5/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.4957 - accuracy: 0.8645 - val_loss: 0.4342 - val_accuracy: 0.8680\n",
      "Epoch 6/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3453 - accuracy: 0.9054 - val_loss: 0.2842 - val_accuracy: 0.9221\n",
      "Epoch 7/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.2493 - accuracy: 0.9310 - val_loss: 0.2027 - val_accuracy: 0.9394\n",
      "Epoch 8/45\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.2000 - accuracy: 0.9451 - val_loss: 0.1246 - val_accuracy: 0.9719\n",
      "Epoch 9/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.1491 - accuracy: 0.9577 - val_loss: 0.0880 - val_accuracy: 0.9762\n",
      "Epoch 10/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.1393 - accuracy: 0.9602 - val_loss: 0.1178 - val_accuracy: 0.9654\n",
      "Epoch 11/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.1058 - accuracy: 0.9696 - val_loss: 0.3630 - val_accuracy: 0.9134\n",
      "Epoch 12/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0918 - accuracy: 0.9747 - val_loss: 0.0811 - val_accuracy: 0.9805\n",
      "Epoch 13/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0839 - accuracy: 0.9768 - val_loss: 0.0678 - val_accuracy: 0.9827\n",
      "Epoch 14/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0652 - accuracy: 0.9817 - val_loss: 0.0705 - val_accuracy: 0.9827\n",
      "Epoch 15/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0689 - accuracy: 0.9807 - val_loss: 0.1305 - val_accuracy: 0.9632\n",
      "Epoch 16/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0559 - accuracy: 0.9837 - val_loss: 0.0776 - val_accuracy: 0.9740\n",
      "Epoch 17/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0420 - accuracy: 0.9879 - val_loss: 0.1272 - val_accuracy: 0.9654\n",
      "Epoch 18/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.1097 - val_accuracy: 0.9784\n",
      "Epoch 19/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0464 - accuracy: 0.9874 - val_loss: 0.0851 - val_accuracy: 0.9719\n",
      "Epoch 20/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.0431 - val_accuracy: 0.9892\n",
      "Epoch 21/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 0.0587 - val_accuracy: 0.9827\n",
      "Epoch 22/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.1110 - val_accuracy: 0.9740\n",
      "Epoch 23/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0446 - val_accuracy: 0.9892\n",
      "Epoch 24/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0360 - accuracy: 0.9903 - val_loss: 0.0771 - val_accuracy: 0.9719\n",
      "Epoch 25/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.0409 - val_accuracy: 0.9913\n",
      "Epoch 26/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.0569 - val_accuracy: 0.9848\n",
      "Epoch 27/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0815 - val_accuracy: 0.9805\n",
      "Epoch 28/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.1062 - val_accuracy: 0.9697\n",
      "Epoch 29/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.1765 - val_accuracy: 0.9567\n",
      "Epoch 30/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.0680 - val_accuracy: 0.9827\n",
      "Epoch 31/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.0316 - val_accuracy: 0.9935\n",
      "Epoch 32/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.1506 - val_accuracy: 0.9654\n",
      "Epoch 33/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0545 - val_accuracy: 0.9870\n",
      "Epoch 34/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 0.0191 - val_accuracy: 0.9957\n",
      "Epoch 35/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.0242 - val_accuracy: 0.9935\n",
      "Epoch 36/45\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0617 - val_accuracy: 0.9870\n",
      "Epoch 37/45\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.1313 - val_accuracy: 0.9654\n",
      "Epoch 38/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.0410 - val_accuracy: 0.9913\n",
      "Epoch 39/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0299 - val_accuracy: 0.9935\n",
      "Epoch 40/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0229 - val_accuracy: 0.9978\n",
      "Epoch 41/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0911 - val_accuracy: 0.9719\n",
      "Epoch 42/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 43/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0340 - val_accuracy: 0.9913\n",
      "Epoch 44/45\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0663 - val_accuracy: 0.9848\n",
      "Epoch 45/45\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0613 - val_accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "epc = 45\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=epc, \n",
    "    batch_size=30, \n",
    "    validation_data=(x_val,y_val),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 도화지 생성\n",
    "fig = plt.figure()\n",
    "# 정확도 그래프 그리기\n",
    "plt.plot(range(epc), history.history['val_accuracy'], label='Accuracy', color='darkred')\n",
    "# 축 이름\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.title('epoch')\n",
    "plt.grid(linestyle='--', color='lavender')\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "# 그래프 저장\n",
    "plt.savefig('sign_launguage_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_predData(path = ['.', 'output', 'tensor', 'prediction']):\n",
    "    prec = []\n",
    "    answer = []\n",
    "    \n",
    "    pred_datas_path = os.path.join(*path)\n",
    "    pred_datas = sorted(os.listdir(pred_datas_path))\n",
    "\n",
    "    for pred_data in pred_datas:\n",
    "        \n",
    "        if pred_data == \"temp\":\n",
    "            continue\n",
    "        pred_data_path = pred_datas_path + \"\\\\\" + pred_data\n",
    "        \n",
    "        for data in os.listdir(pred_data_path):\n",
    "            if data == \"hp.pt\":\n",
    "                continue\n",
    "            prec.append(torch.load(pred_data_path + \"\\\\\" + data))\n",
    "            answer.append(pred_data)\n",
    "            \n",
    "    return prec, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, answer = load_predData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '가끔', '가렵다', '가슴', '감기', '감사합니다', '고열', '골절', '교통사고', '구내염', '귀', '근육통', '눈', '다리', '두드러기', '두통', '등', '따끔거리다', '멍들다', '목', '몸', '몸살', '무릎', '물다', '발목', '부러지다', '붕대', '뼈', '사마귀', '설사', '소화불량', '손', '수술', '심장마비', '쓰러지다', '아프다', '안녕하세요', '어깨', '어지럽다', '얼굴', '열', '의사', '임신', '자주', '찰과상', '코로나', '탈구', '탈모', '토하다', '파상풍', '피', '피부', '허리', '호흡곤란', '화상']\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = matchFrame(prec, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 129, 126)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 126)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(pred, answer):\n",
    "    u = 0\n",
    "    d = 0\n",
    "    \n",
    "    for p, a in zip(pred, answer):\n",
    "        if p == a:\n",
    "            u += 1\n",
    "            d += 1\n",
    "            \n",
    "        else:\n",
    "            d += 1\n",
    "            \n",
    "    return str(u / d) + \"%\"\n",
    "\n",
    "def Correct(a, b):\n",
    "    return True if a == b else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "틀린 단어\n",
      "--------------------------------------------------------\n",
      "answer : 2 , predction : 5\n",
      "answer : 6 , predction : 7\n",
      "answer : 골절 , predction : 화상\n",
      "answer : 목 , predction : 눈\n",
      "answer : 뼈 , predction : 탈구\n",
      "answer : 어깨 , predction : 목\n",
      "answer : 어지럽다 , predction : 귀\n",
      "answer : 탈구 , predction : 찰과상\n",
      "answer : 피부 , predction : 쓰러지다\n",
      "--------------------------------------------------------\n",
      "전체 개수 : 62       틀린 개수 : 9\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "print(\"틀린 단어\")\n",
    "print('--------------------------------------------------------')\n",
    "cnt = 0\n",
    "for prd, ans in zip(model.predict(prec), answer):\n",
    "    prediction.append(answer_set[np.argmax(prd)])\n",
    "    if not Correct(ans, answer_set[np.argmax(prd)]):\n",
    "        cnt += 1\n",
    "        print(\"answer :\", ans, \", predction :\" ,answer_set[np.argmax(prd)])\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print(\"전체 개수 :\", len(prediction), \"      틀린 개수 :\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 0.8548387096774194%\n"
     ]
    }
   ],
   "source": [
    "print(\"정답률 =\", percentage(prediction, answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sh",
   "language": "python",
   "name": "sanghyun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
