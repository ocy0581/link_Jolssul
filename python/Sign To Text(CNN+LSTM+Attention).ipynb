{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17229434045343967050,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 4182996232339474166\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 9534700015733783787\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, warnings, sklearn, matplotlib, torch, time, cv2, math, sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from matplotlib import pyplot\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# GPU-initialization\n",
    "session = None\n",
    "if (session):\n",
    "    session.close()\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(dir_path = [\".\", \"output\", \"tensor\"]):\n",
    "    '''\n",
    "    tensor 가져오는 방식을 csv에서 가져온 번호에서 부터 불러오도록 설정\n",
    "    output 에 nums는 현재 가져온곳의 한글값을 표현하기 위해서 \n",
    "    '''\n",
    "    dir_path = os.path.join(*dir_path)\n",
    "    tensor_folders = sorted(os.listdir(dir_path))\n",
    "    \n",
    "    h_list = []\n",
    "    answers = []\n",
    "    \n",
    "    # 0 ~ 7 순회\n",
    "    for tensor_folder in tensor_folders:\n",
    "        if tensor_folder == \"prediction\":\n",
    "            continue\n",
    "            \n",
    "        if tensor_folder == \"aihub\":\n",
    "            continue\n",
    "                \n",
    "        tensors_path = os.path.join(dir_path + \"\\\\\" + tensor_folder)\n",
    "        tensors = sorted(os.listdir(tensors_path))\n",
    "        \n",
    "        \n",
    "        # 각각의 숫자 순회\n",
    "        for tensor in tensors:                \n",
    "            h_list.append(torch.load(tensors_path + \"\\\\\" + tensor + \"\\\\hand.pt\"))\n",
    "            #h_list.append(torch.load(tensors_path + \"\\\\\" + tensor + \"\\\\hp.pt\"))\n",
    "            answers.append(tensor_folder)\n",
    "            \n",
    "\n",
    "    return h_list, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_list, answers = load_tensor() # 훈련데이터\n",
    "answer_set = list(map(str, sorted(list(set(answers))))) # 정답데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 최대 길이 설정(각 영상의 최대 프레임 추출 후 이를 적용)\n",
    "def matchFrame(lst, max_frame):\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].view(lst[i].shape[0], -1)\n",
    "        lst[i] = np.array(F.pad(lst[i], (0, 0, 0, max_frame - lst[i].shape[0]), value=0))\n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스 최대 길이 출력\n",
    "mx = 0\n",
    "for i in h_list:\n",
    "       mx = max(mx, i.shape[0])\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 최대길이 설정\n",
    "hand_data = matchFrame(h_list, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 126)\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 Shape\n",
    "print(hand_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(hand_data, answers, test_size=0.075, random_state=42)\n",
    "#x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '가끔', '가렵다', '가슴', '감기', '감사합니다', '고열', '골절', '교통사고', '구내염', '귀', '근육통', '눈', '다리', '두드러기', '두통', '등', '따끔거리다', '멍들다', '목', '몸', '몸살', '무릎', '물다', '발목', '부러지다', '붕대', '뼈', '사마귀', '설사', '소화불량', '손', '수술', '심장마비', '쓰러지다', '아프다', '안녕하세요', '어깨', '어지럽다', '얼굴', '열', '의사', '임신', '자주', '찰과상', '코로나', '탈구', '탈모', '토하다', '파상풍', '피', '피부', '허리', '호흡곤란', '화상']\n"
     ]
    }
   ],
   "source": [
    "print(answer_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5697, 129, 126)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 원핫인코딩\n",
    "encoder = LabelBinarizer()\n",
    "test = encoder.fit_transform(answer_set)\n",
    "\n",
    "y_train = encoder.transform(y_train)\n",
    "y_val = encoder.transform(y_val)\n",
    "#y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5697, 62)\n"
     ]
    }
   ],
   "source": [
    "# 정답 데이터 shape\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바다나우 어텐션\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = Dense(units)\n",
    "    self.W2 = Dense(units)\n",
    "    self.V = Dense(1)\n",
    "\n",
    "  def call(self, values, query): # 단, key와 value는 같음\n",
    "    # query shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Unit\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv1D(filters, 3, strides=strides,\n",
    "            \t\t\t\t\tpadding=\"same\", activation = \"relu\",use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            #self.activation,\n",
    "            keras.layers.Conv1D(filters, 3, strides=1,\n",
    "            \t\t\t\t\tpadding=\"same\", use_bias=False),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv1D(filters, 1, strides=strides,\n",
    "                                    padding=\"same\", use_bias=False),\n",
    "                keras.layers.BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 129, 126)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 129, 32)      12128       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 129, 32)      128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 129, 32)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 64, 32)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "residual_unit (ResidualUnit)    (None, 64, 32)       6400        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 31, 32)       0           residual_unit[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "residual_unit_1 (ResidualUnit)  (None, 16, 64)       21248       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 7, 64)        0           residual_unit_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 7, 256)       197632      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 7, 256)       0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 7, 128)       164352      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 128)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 7, 128)       98816       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 128)       0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 7, 128), (No 98816       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt ((None, 128), (None, 16577       bidirectional_3[0][0]            \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        bahdanau_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "class_output (Dense)            (None, 62)           4030        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 628,383\n",
      "Trainable params: 627,807\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "dropout = 0.25\n",
    "num_classes = len(answer_set)\n",
    "nodesizes = [64, 64]\n",
    "\n",
    "inputs = keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "conv1 = keras.layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(\"relu\")(conv1)\n",
    "conv1 = keras.layers.MaxPool1D(pool_size=3, strides=2)(conv1)\n",
    "\n",
    "conv1 = ResidualUnit(32, 1)(conv1)\n",
    "conv1 = keras.layers.MaxPool1D(pool_size=3, strides=2)(conv1)\n",
    "\n",
    "conv1 = ResidualUnit(64, 2)(conv1)\n",
    "conv1 = keras.layers.MaxPool1D(pool_size=3, strides=2)(conv1)\n",
    "\n",
    "lstm = Bidirectional(layers.LSTM(128, return_sequences=True))(conv1)\n",
    "lstm = layers.Dropout(rate=dropout)(lstm)  \n",
    "\n",
    "for i in range(0,2):    #number of layers random between 1 an 3\n",
    "    lstm = Bidirectional(layers.LSTM(nodesizes[i],return_sequences=True))(lstm)\n",
    "    lstm = layers.Dropout(rate=dropout)(lstm)\n",
    "\n",
    "#lstm = Bidirectional(layers.LSTM(256))(lstm)\n",
    "#lstm = layers.Dropout(rate=dropout)(lstm)\n",
    "\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
    "  (layers.LSTM(64, return_sequences=True, return_state=True))(lstm)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
    "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태\n",
    "\n",
    "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
    "\n",
    "context_vector, attention_weights = attention(lstm, state_h)\n",
    "dense1 = Dense(64, activation=\"relu\")(context_vector)\n",
    "dropout = layers.Dropout(0.)(dense1)\n",
    "\n",
    "class_output = layers.Dense(num_classes, activation='softmax', name='class_output')(dense1)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=[class_output])\n",
    "# Plot the model graph\n",
    "keras.utils.plot_model(model, 'nn_graph.png', show_shapes=True)\n",
    "\n",
    "model.compile(loss={\n",
    "    'class_output': 'categorical_crossentropy', \n",
    "    },\n",
    "    optimizer='Adamax',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "190/190 [==============================] - 9s 46ms/step - loss: 3.3085 - accuracy: 0.1455 - val_loss: 2.8204 - val_accuracy: 0.1818\n",
      "Epoch 2/35\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 1.7220 - accuracy: 0.5375 - val_loss: 1.3803 - val_accuracy: 0.6212\n",
      "Epoch 3/35\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.9514 - accuracy: 0.7636 - val_loss: 1.3358 - val_accuracy: 0.6234\n",
      "Epoch 4/35\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.5771 - accuracy: 0.8497 - val_loss: 0.7328 - val_accuracy: 0.7749\n",
      "Epoch 5/35\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3927 - accuracy: 0.8870 - val_loss: 0.8983 - val_accuracy: 0.7273\n",
      "Epoch 6/35\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.2980 - accuracy: 0.9103 - val_loss: 0.8392 - val_accuracy: 0.7619\n",
      "Epoch 7/35\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.2354 - accuracy: 0.9245 - val_loss: 0.2889 - val_accuracy: 0.8983\n",
      "Epoch 8/35\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.1667 - accuracy: 0.9473 - val_loss: 0.2226 - val_accuracy: 0.9221\n",
      "Epoch 9/35\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.1538 - accuracy: 0.9559 - val_loss: 0.1903 - val_accuracy: 0.9502\n",
      "Epoch 10/35\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.1010 - accuracy: 0.9731 - val_loss: 0.1197 - val_accuracy: 0.9697\n",
      "Epoch 11/35\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0945 - accuracy: 0.9737 - val_loss: 0.1905 - val_accuracy: 0.9351\n",
      "Epoch 12/35\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0757 - accuracy: 0.9803 - val_loss: 0.4911 - val_accuracy: 0.8701\n",
      "Epoch 13/35\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.0789 - accuracy: 0.9781 - val_loss: 1.8787 - val_accuracy: 0.6623\n",
      "Epoch 14/35\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.0647 - accuracy: 0.9824 - val_loss: 1.6243 - val_accuracy: 0.7273\n",
      "Epoch 15/35\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0553 - accuracy: 0.9851 - val_loss: 0.2511 - val_accuracy: 0.9416\n",
      "Epoch 16/35\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.0331 - accuracy: 0.9935 - val_loss: 0.0663 - val_accuracy: 0.9740\n",
      "Epoch 17/35\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.0332 - accuracy: 0.9914 - val_loss: 0.2027 - val_accuracy: 0.9481\n",
      "Epoch 18/35\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 1.5514 - val_accuracy: 0.7251\n",
      "Epoch 19/35\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 0.4120 - val_accuracy: 0.9004\n",
      "Epoch 20/35\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.1046 - val_accuracy: 0.9697\n",
      "Epoch 21/35\n",
      " 84/190 [============>.................] - ETA: 3s - loss: 0.0195 - accuracy: 0.9964"
     ]
    }
   ],
   "source": [
    "epc = 35\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=epc, \n",
    "    batch_size=30, \n",
    "    validation_data=(x_val,y_val),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도화지 생성\n",
    "fig = plt.figure()\n",
    "# 정확도 그래프 그리기\n",
    "plt.plot(range(epc), history.history['val_accuracy'], label='Accuracy', color='darkred')\n",
    "# 축 이름\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.title('epoch')\n",
    "plt.grid(linestyle='--', color='lavender')\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "# 그래프 저장\n",
    "plt.savefig('sign_launguage_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_predData(path = ['.', 'output', 'tensor', 'prediction']):\n",
    "    prec = []\n",
    "    answer = []\n",
    "    \n",
    "    pred_datas_path = os.path.join(*path)\n",
    "    pred_datas = sorted(os.listdir(pred_datas_path))\n",
    "\n",
    "    for pred_data in pred_datas:\n",
    "        \n",
    "        if pred_data == \"temp\":\n",
    "            continue\n",
    "        pred_data_path = pred_datas_path + \"\\\\\" + pred_data\n",
    "        \n",
    "        for data in os.listdir(pred_data_path):\n",
    "            if data == \"hp.pt\":\n",
    "                continue\n",
    "            prec.append(torch.load(pred_data_path + \"\\\\\" + data))\n",
    "            answer.append(pred_data)\n",
    "            \n",
    "    return prec, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, answer = load_predData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = matchFrame(prec, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(pred, answer):\n",
    "    u = 0\n",
    "    d = 0\n",
    "    \n",
    "    for p, a in zip(pred, answer):\n",
    "        if p == a:\n",
    "            u += 1\n",
    "            d += 1\n",
    "            \n",
    "        else:\n",
    "            d += 1\n",
    "            \n",
    "    return str(u / d) + \"%\"\n",
    "\n",
    "def Correct(a, b):\n",
    "    if '코로나' in a: a = a[:3]\n",
    "    return True if a == b else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "print(\"틀린 단어\")\n",
    "print('--------------------------------------------------------')\n",
    "cnt = 0\n",
    "for prd, ans in zip(model.predict(prec), answer):\n",
    "    prediction.append(answer_set[np.argmax(prd)])\n",
    "    if not Correct(ans, answer_set[np.argmax(prd)]):\n",
    "        cnt += 1\n",
    "        print(\"answer :\", ans, \", predction :\" ,answer_set[np.argmax(prd)])\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print(\"전체 개수 :\", len(prediction), \"      틀린 개수 :\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"정답률 =\", percentage(prediction, answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sh",
   "language": "python",
   "name": "sanghyun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
